{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3932ef0f-e576-4f2c-b4df-a46e4c8c1659",
   "metadata": {},
   "source": [
    "### YouTube Channel Name & Link Scraper\r\n",
    "\r\n",
    "This script pulls channel names and links from a YouTube search and checks them against an existing list in `Influencers.xlsx`. It skips any repeats, and only the new entries are saved to a new Excel file.\r\n",
    "\r\n",
    "**Edit `search_url` as required.**\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "### Requirements\r\n",
    "\r\n",
    "- `selenium`\r\n",
    "- `pandas`\r\n",
    "- `openpyxl`\r\n",
    "- ChromeDriver (must match your Chrome version)\r\n",
    "on)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ede11e-c463-4592-9f61-25eb45292c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total scraped: 407\n",
      "Removed known: 7\n",
      "New unique channels: 400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Name</th>\n",
       "      <th>Channel Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anu Choudhary Vlogs</td>\n",
       "      <td>https://www.youtube.com/@anu_choudhary_vlogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sindhu Family</td>\n",
       "      <td>https://www.youtube.com/@SindhuFamily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Simran &amp; Gaurav Vlogs</td>\n",
       "      <td>https://www.youtube.com/@simransingh20029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mom Com India</td>\n",
       "      <td>https://www.youtube.com/@MomComIndia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Annabell Newman</td>\n",
       "      <td>https://www.youtube.com/@AnnabellNewman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Channel Name                                  Channel Link\n",
       "0    Anu Choudhary Vlogs  https://www.youtube.com/@anu_choudhary_vlogs\n",
       "1          Sindhu Family         https://www.youtube.com/@SindhuFamily\n",
       "2  Simran & Gaurav Vlogs     https://www.youtube.com/@simransingh20029\n",
       "3          Mom Com India          https://www.youtube.com/@MomComIndia\n",
       "4        Annabell Newman       https://www.youtube.com/@AnnabellNewman"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "from openpyxl.styles import Font\n",
    "from openpyxl.worksheet.hyperlink import Hyperlink\n",
    "\n",
    "#Edit as needed\n",
    "search_url = \"https://www.youtube.com/results?search_query=baby+routine+vlog+india\"\n",
    "output_excel= \"channels_with_links.xlsx\"\n",
    "\n",
    "# Load entries from existing dataset\n",
    "df = pd.read_excel(\"Influencers.xlsx\", usecols=\"A\")\n",
    "known_channels = set(df.iloc[:, 0].dropna().astype(str).str.strip())\n",
    "\n",
    "# Setup Chrome headless\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "driver.get(search_url)\n",
    "time.sleep(5)\n",
    "\n",
    "# Scroll until no more new content\n",
    "last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
    "    time.sleep(3)\n",
    "    current_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
    "    if current_height == last_height:\n",
    "        break\n",
    "    last_height = current_height\n",
    "\n",
    "# Extract channel names and links\n",
    "channel_elements = driver.find_elements(By.CSS_SELECTOR, \"ytd-channel-name a.yt-simple-endpoint\")\n",
    "channels = []\n",
    "for elem in channel_elements:\n",
    "    name = elem.text.strip()\n",
    "    link = elem.get_attribute(\"href\")\n",
    "    if name:\n",
    "        channels.append({\"Channel Name\": name, \"Channel Link\": link})\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "#Removed any channels which are also present in influencers.xlsx and also duplicated from search result query\n",
    "df_channels = pd.DataFrame(channels)\n",
    "df_channels = df_channels.drop_duplicates(subset=[\"Channel Name\"])\n",
    "df_channels[\"Channel Name\"] = df_channels[\"Channel Name\"].astype(str).str.strip()\n",
    "new_channels = df_channels[~df_channels[\"Channel Name\"].isin(known_channels)].reset_index(drop=True)\n",
    "new_channels.to_excel(output_excel, index=False)\n",
    "\n",
    "print(f\"Total scraped: {len(df_channels)}\")\n",
    "print(f\"Removed known: {len(df_channels) - len(new_channels)}\")\n",
    "print(f\"New unique channels: {len(new_channels)}\")\n",
    "new_channels.head()\n",
    "\n",
    "# Fix excel hyperlinks not working\n",
    "wb = load_workbook(output_excel)\n",
    "ws = wb.active\n",
    "\n",
    "# Assuming headers in first row: \"Channel Name\" in A, \"Channel Link\" in B\n",
    "for row in range(2, ws.max_row + 1):\n",
    "    link = ws[f\"B{row}\"].value\n",
    "    if link:\n",
    "        ws[f\"B{row}\"].hyperlink = link\n",
    "        ws[f\"B{row}\"].font = Font(color=\"0000EE\", underline=\"single\")\n",
    "\n",
    "wb.save(output_excel)\n",
    "new_channels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ba9295-79e8-4e8e-aa6f-c75ff87dfe07",
   "metadata": {},
   "source": [
    "\n",
    "## YouTube Channel Scraper with Periodic User-Agent Rotation and Anti-Detection Measures\n",
    "\n",
    "This script scrapes subscriber and video counts from YouTube channel pages listed \n",
    "in an input Excel file. It uses undetected_chromedriver with randomized user-agents \n",
    "to help avoid detection by anti-bot systems.\n",
    "\n",
    "- Runs Chrome in incognito mode\n",
    "- Avoids headless mode by default to reduce blocking risk.\n",
    "- Implements randomized delays between requests to mimic human behavior.\n",
    "- Retries loading channel pages up to 3 times if elements are not found.\n",
    "\n",
    "### Usage:\n",
    "- Run the script and provide the input Excel filename when prompted.\n",
    "- Input excel should contain two columns: 'Channel Name' and 'Channel Link'.\n",
    "- Provide a name for the output Excel file, where subscriber and video counts will be saved.\n",
    "\n",
    "### Note:\n",
    "- Running headless mode can increase the chance of being blocked.\n",
    "- Adjust random wait times and agent rotation interval as needed.\n",
    "\n",
    "### Dependencies:\n",
    "- pandas\n",
    "- selenium\n",
    "- undetected_chromedriver\n",
    "- fake_useragent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f3fd50-59aa-47d0-8a61-65487fe76632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changing user-agent at iteration 0: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36\n",
      "Processing: Anu Choudhary Vlogs - https://www.youtube.com/@anu_choudhary_vlogs\n",
      "Waiting for elements, attempt 1 on URL: https://www.youtube.com/@anu_choudhary_vlogs\n",
      "Subscribers: 210K subscribers, Videos: 294 videos\n",
      "Processing: Sindhu Family - https://www.youtube.com/@SindhuFamily\n",
      "Waiting for elements, attempt 1 on URL: https://www.youtube.com/@SindhuFamily\n",
      "Subscribers: 2.47K subscribers, Videos: 633 videos\n",
      "Processing: Simran & Gaurav Vlogs - https://www.youtube.com/@simransingh20029\n",
      "Waiting for elements, attempt 1 on URL: https://www.youtube.com/@simransingh20029\n",
      "Subscribers: 14.3K subscribers, Videos: 227 videos\n",
      "Processing: Mom Com India - https://www.youtube.com/@MomComIndia\n",
      "Waiting for elements, attempt 1 on URL: https://www.youtube.com/@MomComIndia\n",
      "Subscribers: 3.3M subscribers, Videos: 1.9K videos\n",
      "Processing: Annabell Newman - https://www.youtube.com/@AnnabellNewman\n",
      "Waiting for elements, attempt 1 on URL: https://www.youtube.com/@AnnabellNewman\n",
      "Subscribers: 31.9K subscribers, Videos: 880 videos\n",
      "Processing: Indian home vlogs with Rajni - https://www.youtube.com/@Indianhomevlogswithrajni\n",
      "Waiting for elements, attempt 1 on URL: https://www.youtube.com/@Indianhomevlogswithrajni\n",
      "Subscribers: 96.9K subscribers, Videos: 1.5K videos\n",
      "Processing: Divija & Shrija - https://www.youtube.com/@Divija.wanole\n",
      "Waiting for elements, attempt 1 on URL: https://www.youtube.com/@Divija.wanole\n",
      "Subscribers: 75.4K subscribers, Videos: 444 videos\n",
      "Processing: Indian mom in Dubai UK & Canada - https://www.youtube.com/@IndianmominDubai\n",
      "Waiting for elements, attempt 1 on URL: https://www.youtube.com/@IndianmominDubai\n",
      "Subscribers: 552K subscribers, Videos: 485 videos\n",
      "Saved updated data to youtube_channel_data_enriched.xlsx\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import undetected_chromedriver as uc\n",
    "\n",
    "#Replace paths as required\n",
    "input_excel = \"channels_with_links.xlsx\"\n",
    "output_excel = \"youtube_channel_data_enriched.xlsx\"\n",
    "\n",
    "# Function to setup ChromeDriver with fake useragent and options\n",
    "def setup_driver():\n",
    "    ua = UserAgent()\n",
    "    options = uc.ChromeOptions()\n",
    "    user_agent = ua.chrome\n",
    "    options.add_argument(f'user-agent={user_agent}')\n",
    "    options.add_argument('--incognito')\n",
    "    \n",
    "    '''\n",
    "    Running in headless mode can increase the risk of being blocked by anti-bot systems.  \n",
    "    If you plan to scrape more than 100 channels, it’s best to keep headless mode disabled.  \n",
    "    To enable headless mode, simply remove the comment (#) from the line below.\n",
    "    '''\n",
    "    # options.add_argument('--headless')\n",
    "\n",
    "\n",
    "    # Additional options for avoiding detection\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-infobars')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    \n",
    "    driver = uc.Chrome(options=options)\n",
    "    driver.set_window_size(1200, 800)\n",
    "    return driver\n",
    "\n",
    "def random_wait(min_sec=3, max_sec=7):\n",
    "    time.sleep(random.uniform(min_sec, max_sec))\n",
    "\n",
    "def get_subscriber_and_video_counts(driver, url, max_retries=3):\n",
    "    new_ua = UserAgent().chrome\n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": new_ua})\n",
    "    driver.get(url)\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            print(f\"Waiting for elements, attempt {attempt+1} on URL: {url}\")\n",
    "            wait = WebDriverWait(driver, 20)\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.yt-content-metadata-view-model-wiz__metadata-row\")))\n",
    "\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, \"div.yt-content-metadata-view-model-wiz__metadata-row span\")\n",
    "\n",
    "            subs_text = \"Subscriber count not found\"\n",
    "            videos_text = \"Video count not found\"\n",
    "            for elem in elements:\n",
    "                text = elem.text.strip()\n",
    "                if 'subscribers' in text:\n",
    "                    subs_text = text\n",
    "                elif 'videos' in text:\n",
    "                    videos_text = text\n",
    "\n",
    "            return subs_text, videos_text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt+1} failed for {url}. Refreshing page and retrying...\")\n",
    "            driver.refresh()\n",
    "            attempt += 1\n",
    "            time.sleep(5)\n",
    "\n",
    "    return \"Error: Subscriber count not found after retries\", \"Error: Video count not found after retries\"\n",
    "\n",
    "def main(input_excel_path, output_excel_path):\n",
    "    df = pd.read_excel(input_excel_path)\n",
    "\n",
    "    driver = setup_driver()\n",
    "\n",
    "    subscriber_counts = []\n",
    "    video_counts = []\n",
    "    \n",
    "    # Interval for agent change (random between 20-25) (helps in avoiding detection)\n",
    "    change_interval = random.randint(20, 25)\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Change user-agent and restart driver at interval\n",
    "        if idx % change_interval == 0:\n",
    "            if driver:\n",
    "                driver.quit()\n",
    "            ua = UserAgent()\n",
    "            user_agent = ua.chrome\n",
    "            print(f\"Changing user-agent at iteration {idx}: {user_agent}\")\n",
    "            \n",
    "            options = uc.ChromeOptions()\n",
    "            options.add_argument(f'user-agent={user_agent}')\n",
    "            options.add_argument('--incognito')\n",
    "            options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "            options.add_argument('--no-sandbox')\n",
    "            options.add_argument('--disable-infobars')\n",
    "            options.add_argument('--disable-dev-shm-usage')\n",
    "            driver = uc.Chrome(options=options)\n",
    "            driver.set_window_size(1200, 800)\n",
    "            \n",
    "            change_interval = idx + random.randint(20, 25)\n",
    "            \n",
    "        channel_name = row['Channel Name']\n",
    "        channel_link = row['Channel Link']\n",
    "\n",
    "        print(f\"Processing: {channel_name} - {channel_link}\")\n",
    "        subs, videos = get_subscriber_and_video_counts(driver, channel_link)\n",
    "        print(f\"Subscribers: {subs}, Videos: {videos}\")\n",
    "        subscriber_counts.append(subs)\n",
    "        video_counts.append(videos)\n",
    "        \n",
    "        # Random wait to avoid detection\n",
    "        random_wait(3,7)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    df['Subscriber Count'] = subscriber_counts\n",
    "    df['Video Count'] = video_counts\n",
    "\n",
    "    df.to_excel(output_excel_path, index=False)\n",
    "    # Fixing excel links. (Assuming header \"Channel Link\" in column B)\n",
    "    wb = load_workbook(output_excel_path)\n",
    "    ws = wb.active\n",
    "    for row in range(2, ws.max_row + 1):\n",
    "        link = ws[f\"B{row}\"].value\n",
    "        if link:\n",
    "            ws[f\"B{row}\"].hyperlink = link\n",
    "            ws[f\"B{row}\"].font = Font(color=\"0000EE\", underline=\"single\")\n",
    "\n",
    "    wb.save(output_excel_path)\n",
    "    print(f\"Saved updated data to {output_excel_path}\")\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main(input_excel, output_excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2944aba4-1ee2-4bfc-b4d3-5a6fa170921f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
